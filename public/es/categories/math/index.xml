<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Math on Matias Di Bernardo</title>
        <link>http://localhost:1313/es/categories/math/</link>
        <description>Recent content in Math on Matias Di Bernardo</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>es</language>
        <copyright>Matías Di Bernardo</copyright>
        <lastBuildDate>Wed, 23 Aug 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/es/categories/math/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Entendiendo FastPitch y la arquitectura Transformers</title>
        <link>http://localhost:1313/es/p/entendiendo-fastpitch-y-la-arquitectura-transformers/</link>
        <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/es/p/entendiendo-fastpitch-y-la-arquitectura-transformers/</guid>
        <description>&lt;img src="http://localhost:1313/p/understanding-fastpitch-and-the-transformer-architecture/front.png" alt="Featured image of post Entendiendo FastPitch y la arquitectura Transformers" /&gt;&lt;p&gt;Entender un modelo moderno de deep learning no es sencillo debido a la gran cantidad de conocimiento previo necesario y al rápido ritmo de avance en este campo. En el proyecto de investigación &lt;em&gt;Intercambios Transorgánicos&lt;/em&gt;, estamos trabajando con TTS, específicamente con el modelo FastPitch de Nvidia. He estudiado este modelo para ajustarlo (fine-tuning) al español y he compartido este proceso de investigación en una clase para ayudar a mis colegas del grupo de investigación a comprenderlo mejor.&lt;/p&gt;
&lt;h2 id=&#34;entendiendo-los-modelos-seq2seq&#34;&gt;Entendiendo los Modelos Seq2Seq
&lt;/h2&gt;&lt;p&gt;En &lt;em&gt;Intercambios Transorgánicos&lt;/em&gt; utilizábamos previamente Tacotron2 como modelo TTS. Este modelo funciona bien, pero presenta varios problemas, principalmente durante el entrenamiento y la inferencia, debido a su naturaleza auto-regresiva. En contraste, FastPitch es un modelo no auto-regresivo (NAR). Para entender estas diferencias, exploré en profundidad los modelos seq2seq, analizando su evolución a lo largo del tiempo, y realicé un resumen rápido de los modelos de análisis de secuencias más relevantes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RNN&lt;/li&gt;
&lt;li&gt;LSTM&lt;/li&gt;
&lt;li&gt;Transformers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tacotron2 se basa en un modelo LSTM (AR), mientras que FastPitch utiliza Transformers (NAR). Comprender esta progresión tecnológica proporciona un contexto esencial, especialmente sobre los transformers, incluyendo la codificación posicional, un elemento clave para su naturaleza no auto-regresiva, y el mecanismo de atención.&lt;/p&gt;
&lt;h2 id=&#34;la-arquitectura-transformer&#34;&gt;La Arquitectura Transformer
&lt;/h2&gt;&lt;p&gt;Comencé estudiando la arquitectura transformer, ya que es fundamental para el modelo FastPitch. Revisé recursos en línea y el influyente artículo &lt;em&gt;Attention is All You Need&lt;/em&gt;. A continuación, algunos puntos clave que anoté durante mi estudio:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mecanismo de Auto-Atención&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Propósito&lt;/strong&gt;: Focalizar dinámicamente en diferentes partes de la secuencia de entrada.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mecanismo&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Query (Q), Key (K), Value (V): Derivados de las embeddings de entrada.&lt;/li&gt;
&lt;li&gt;Los puntajes de atención se calculan como el producto punto de Q y K, escalado por la raíz cuadrada de la dimensión.&lt;/li&gt;
&lt;li&gt;Los puntajes se normalizan con softmax para generar pesos de atención.&lt;/li&gt;
&lt;li&gt;Se calcula una suma ponderada de V basada en estos pesos para producir la salida.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Atención Multi-Cabezal&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Propósito&lt;/strong&gt;: Capturar diferentes relaciones entre tokens aplicando múltiples mecanismos de auto-atención en paralelo.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mecanismo&lt;/strong&gt;: Las salidas de las múltiples cabezas de atención se concatenan y se transforman linealmente.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Codificación Posicional&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Propósito&lt;/strong&gt;: Añadir información sobre el orden de los tokens en la secuencia, compensando la falta de un concepto incorporado de orden secuencial en los Transformers (a diferencia de los RNNs).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mecanismo&lt;/strong&gt;: Se añade un vector fijo o aprendible a las embeddings de entrada.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Estructura Codificador-Descodificador&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Codificador&lt;/strong&gt;: Procesa la secuencia de entrada en representaciones ricas en contexto.
&lt;ul&gt;
&lt;li&gt;Componentes:
&lt;ul&gt;
&lt;li&gt;Auto-atención multi-cabezal&lt;/li&gt;
&lt;li&gt;Red neuronal feed-forward (FFN)&lt;/li&gt;
&lt;li&gt;Normalización por capas y conexiones residuales&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Descodificador&lt;/strong&gt;: Genera la secuencia de salida atendiendo tanto a las salidas del codificador como a los tokens generados previamente.
&lt;ul&gt;
&lt;li&gt;Componentes:
&lt;ul&gt;
&lt;li&gt;Auto-atención multi-cabezal enmascarada (evita atender a tokens futuros)&lt;/li&gt;
&lt;li&gt;Atención multi-cabezal sobre las salidas del codificador&lt;/li&gt;
&lt;li&gt;FFN, normalización por capas y conexiones residuales&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Red Feed-Forward (FFN)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Propósito&lt;/strong&gt;: Introducir no linealidad y procesar cada token de manera independiente.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mecanismo&lt;/strong&gt;: Dos capas lineales con una activación ReLU entre ellas.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Normalización por Capas y Conexiones Residuales&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Propósito&lt;/strong&gt;: Estabilizar el entrenamiento y mejorar el flujo de gradientes al normalizar las entradas de cada capa y añadir conexiones de salto.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;fastpitch&#34;&gt;FastPitch
&lt;/h2&gt;&lt;p&gt;Con la teoría cubierta, examiné cada sección de la arquitectura de FastPitch en detalle. Ofrecí una breve explicación sobre las embeddings de palabras y la codificación posicional, ya que son temas complejos, y quise mantener la clase concisa.&lt;/p&gt;
&lt;p&gt;FastPitch convierte texto en espectrogramas mel, que luego son transformados en audio por otro modelo (en nuestro caso, HiFi-GAN). La secuencia de entrenamiento incluye los siguientes pasos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Texto a embeddings de palabras&lt;/li&gt;
&lt;li&gt;Concatenación de embeddings de palabras con espectrogramas mel&lt;/li&gt;
&lt;li&gt;Codificación posicional y FFT (bloque Transformer Feed-Forward)&lt;/li&gt;
&lt;li&gt;Predicción de tono&lt;/li&gt;
&lt;li&gt;Predicción de la duración de los fonemas&lt;/li&gt;
&lt;li&gt;Otro bloque FFT&lt;/li&gt;
&lt;li&gt;Capa completamente conectada&lt;/li&gt;
&lt;li&gt;Salida del espectrograma mel&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;En cada bloque, presenté las ecuaciones correspondientes y proporcioné explicaciones cualitativas sobre su rol en el modelo. Por ejemplo, la predicción de la duración de los fonemas es crucial para alinear la duración de un fonema con la duración esperada en el espectrograma.&lt;/p&gt;
&lt;h2 id=&#34;clase-online&#34;&gt;Clase Online
&lt;/h2&gt;&lt;p&gt;Finalmente, resumí los puntos más importantes y realicé una clase online para compartir estos conceptos con mis colegas. Puedes verla aquí:&lt;/p&gt;
&lt;div class=&#34;video-wrapper&#34;&gt;
    &lt;iframe loading=&#34;lazy&#34; 
            src=&#34;https://www.youtube.com/embed/v4bt8bGIM00&#34; 
            allowfullscreen 
            title=&#34;YouTube Video&#34;
    &gt;
    &lt;/iframe&gt;
&lt;/div&gt;

</description>
        </item>
        <item>
        <title>Comparación de diferentes transformaciones tiempo-frecuencia</title>
        <link>http://localhost:1313/es/p/comparaci%C3%B3n-de-diferentes-transformaciones-tiempo-frecuencia/</link>
        <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/es/p/comparaci%C3%B3n-de-diferentes-transformaciones-tiempo-frecuencia/</guid>
        <description>&lt;img src="http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/fourier.jpg" alt="Featured image of post Comparación de diferentes transformaciones tiempo-frecuencia" /&gt;&lt;p&gt;Esta investigación se desarrolla en el marco de la materia &lt;em&gt;Metodología de la Investigación&lt;/em&gt; en UNTREF. En el artículo se pretende comparar las diferencias entre tres tipos de transformaciones tiempo-frecuencia:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Transformada de Fourier (FT)&lt;/li&gt;
&lt;li&gt;Transformada Wavelet (WT)&lt;/li&gt;
&lt;li&gt;Transformada Huang-Hilbert (HHT)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;El objetivo del trabajo es entender las diferencias entre estos tipos de transformaciones y profundizar mi conocimiento en el procesamiento de señales.&lt;/p&gt;
&lt;h2 id=&#34;objetivo&#34;&gt;Objetivo
&lt;/h2&gt;&lt;p&gt;El objetivo general de la investigación es determinar con qué herramienta de análisis espectral se logra una mayor precisión en la tarea de detección de tono.&lt;/p&gt;
&lt;p&gt;Para alcanzar este objetivo, se plantean los siguientes puntos a completar:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Determinar los parámetros necesarios para representar la señal en el dominio espectral según cada caso.&lt;/li&gt;
&lt;li&gt;Elegir un algoritmo que identifique el tono de la señal en base a su representación espectral.&lt;/li&gt;
&lt;li&gt;Generar los datos (señales de audio) con los cuales se realizará la comparación.&lt;/li&gt;
&lt;li&gt;Evaluar los datos generados con los distintos métodos de análisis y aplicar procesos estadísticos para validar los resultados.&lt;/li&gt;
&lt;li&gt;Establecer una medida de precisión en la tarea de detección de tono.&lt;/li&gt;
&lt;li&gt;Comparar los resultados de los distintos análisis y determinar cuál es el que consigue una mayor precisión en la detección de tono.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se eligió la tarea de detección de tono porque es una de las aplicaciones principales de este tipo de transformadas.&lt;/p&gt;
&lt;h2 id=&#34;algoritmos&#34;&gt;Algoritmos
&lt;/h2&gt;&lt;p&gt;El análisis teórico de todas las transformadas se realiza en el dominio continuo, pero para llevar a cabo los experimentos y comparaciones se trabaja en el dominio discreto, de forma que todos los cálculos se realizan digitalmente.&lt;/p&gt;
&lt;h3 id=&#34;fft&#34;&gt;FFT
&lt;/h3&gt;&lt;p&gt;La FFT es un algoritmo que optimiza la DFT (Transformada de Fourier de tiempo discreto). Con este algoritmo se obtiene la representación espectral de la señal de acuerdo al análisis de Fourier, descomponiendo una señal compleja en una suma de senos o cosenos. La DFT se calcula mediante la fórmula:&lt;/p&gt;
$$
X_k = \sum_{n=0}^{N-1} e^{-i\frac{2\pi}{N}kn} x_n
$$&lt;p&gt;Donde \( N \) es la cantidad de muestras de la señal y \( k \) son los números naturales de \( 0 \) hasta \( N – 1 \).&lt;/p&gt;
&lt;h3 id=&#34;wt&#34;&gt;WT
&lt;/h3&gt;&lt;p&gt;La Transformada Wavelet (WT) utiliza una función ondulatoria (wavelet) y aplica una convolución entre la señal y la función de onda elegida para determinar si esa forma ondulatoria está presente en la señal. La onda se deforma en frecuencia y amplitud, permitiendo que una sola función ondulatoria recree todo el espectro de interés.&lt;/p&gt;
&lt;p&gt;Para esta investigación se empleará la CDWT (Cyclic Discrete Wavelet Transform), la implementación más común al discretizar la WT. Conceptualmente, esta transformada extiende el análisis de Fourier utilizando una base de funciones ondulatorias en lugar de senos y cosenos. Se calcula así:&lt;/p&gt;
$$
Wf[n, a^j] = \sum_{m=0}^{N-1} f[m] \psi_j[m-n]
$$&lt;p&gt;Donde \( N \) es la cantidad de muestras de la señal, \( \psi \) es la función ondulatoria y \( j \) representa la deformación de la onda según el banco de ondas seleccionado.&lt;/p&gt;
&lt;h3 id=&#34;hht&#34;&gt;HHT
&lt;/h3&gt;&lt;p&gt;Por último, se empleará la Transformada Huang-Hilbert (HHT), que utiliza la Descomposición Empírica Modal (EMD) para descomponer la señal en subseñales relevantes. En lugar de descomponer en funciones senoidales u ondulatorias, el EMD encuentra funciones modales intrínsecas (IMF) específicas de cada señal.&lt;/p&gt;
&lt;p&gt;La relación entre las IMF y la frecuencia original se establece con la ecuación:&lt;/p&gt;
$$
z(t) = f(t) + i H\{ f(t) \}
$$&lt;p&gt;Donde \( f(t) \) es una IMF y \( H \) es la Transformada Hilbert. Esto permite proyectar la señal al eje imaginario y extraer la amplitud y la fase de cada instante, construyendo la representación espectral. Como una señal generalmente tiene múltiples IMF, este proceso se repite para todas y se suman para obtener el espectro completo.&lt;/p&gt;
&lt;h2 id=&#34;procedimiento&#34;&gt;Procedimiento
&lt;/h2&gt;&lt;p&gt;Se analizará la relación entre los tipos de representación espectral y la precisión en la detección de tono.&lt;/p&gt;
&lt;p&gt;Primero, se seleccionarán los parámetros para las distintas transformadas, como el número de muestras para el ventaneo temporal, que determina la resolución temporal y frecuencial.&lt;/p&gt;
&lt;p&gt;Para comparar los métodos, se generarán datos representativos de distintos casos de interés, modelando cuatro tipos de señales:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Monótonas&lt;/strong&gt;: Una sola nota correspondiente a la \( F_0 \).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Politonales&lt;/strong&gt;: Múltiples notas, donde la armonía determina la \( F_0 \).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transiciones lentas&lt;/strong&gt;: Cambios de \( F_0 \) graduales.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transiciones rápidas&lt;/strong&gt;: Cambios de \( F_0 \) abruptos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se comparará el valor real \( V(t) \) con el resultado \( P(t) \) de cada transformada, integrando la diferencia temporalmente para calcular la precisión.&lt;/p&gt;
&lt;h2 id=&#34;resultados&#34;&gt;Resultados
&lt;/h2&gt;&lt;p&gt;En esta etapa, solo se requería completar el plan de investigación detallando el procedimiento y los métodos de análisis. Para ello, se generaron datos de ejemplo (&lt;em&gt;dummy data&lt;/em&gt;) y se validaron estadísticamente los resultados esperados.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/res.PNG&#34;
	width=&#34;834&#34;
	height=&#34;550&#34;
	srcset=&#34;http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/res_hu8387233291062647437.PNG 480w, http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/res_hu2809804783985204141.PNG 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Gráfico con la precisión de cada transformada según el tipo de señal analizada&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;363px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;El gráfico muestra la precisión obtenida con las tres transformadas en función del tipo de señal. Se espera que la Transformada Wavelet (WT) supere a la Transformada de Fourier (FT), y que la Transformada Huang-Hilbert (HHT) sea más precisa en general.&lt;/p&gt;
&lt;h2 id=&#34;conclusiones&#34;&gt;Conclusiones
&lt;/h2&gt;&lt;p&gt;En la tarea de detección de tono por análisis frecuencial, la Transformada Huang-Hilbert (HHT) ofrece, en la mayoría de los casos, mayor precisión que la Transformada Rápida de Fourier (FFT) y la Transformada Wavelet Cíclica (CDWT).&lt;/p&gt;
&lt;p&gt;La magnitud de esta diferencia depende del tipo de señal analizada, siendo las señales con transiciones rápidas las menos beneficiadas por el cambio de transformada, mientras que las señales politonales muestran las mejoras más significativas al emplear la HHT.&lt;/p&gt;
&lt;p&gt;En este proyecto, profundicé mis conocimientos en procesamiento de señales y comprendí los fundamentos para usar herramientas como la WT y la HHT según las características de la señal.&lt;/p&gt;
&lt;p&gt;Más detalles del trabajo están disponibles en el siguiente &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1G5kasP3BzZPVuxrXArHM72pUVlkN9b2Q/view?usp=sharing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;informe&lt;/a&gt;.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
