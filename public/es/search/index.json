[{"content":"Medidor THD+N Un medidor de THD+N mide la distorsión armónica de un dispositivo. En audio, esto es crucial para evaluar la calidad del equipo. Este proyecto fue desarrollado como parte de la asignatura \u0026ldquo;Instrumentos y Mediciones Electrónicas\u0026rdquo; en UNTREF. En este curso, los estudiantes diseñan y desarrollan diversos instrumentos electrónicos, y los proyectos son continuados por grupos sucesivos de estudiantes. Este proyecto en particular ya estaba en marcha, y nuestro enfoque fue desarrollar un desfasador para alinear dos señales.\nTeoría sobre como medición de THD Para medir la distorsión de un sistema, se introduce una señal sinusoidal con la menor distorsión posible al dispositivo bajo prueba. El objetivo es evaluar cuánta distorsión agrega el dispositivo a la señal. Esto se cuantifica midiendo la potencia de la señal original y la potencia de la señal después de pasar por el dispositivo, excluyendo la armónica fundamental.\nUn amplificador diferencial se utiliza para restar la señal de salida del dispositivo de la señal de referencia, dejando solo las armónicas de orden superior.\nEl THD+N se calcula luego como un porcentaje usando la siguiente ecuación:\n$$\rTHD+N = \\frac{V_{filt}}{V_{tot}} \\cdot 100\r$$Donde: $V_{filt}$ es el valor RMS de la señal filtrada (excluyendo la armónica fundamental). $V_{tot}$ es el valor RMS de la señal original.\nDesfasador Para lograr una cancelación efectiva en la sección diferencial, se requieren ajustes precisos de fase y ganancia de las dos señales. El ajuste de ganancia había sido implementado con éxito por el grupo anterior que trabajó en el proyecto. Sin embargo, lograr la rotación de fase necesaria de 360 grados en toda la gama de frecuencias audibles (20 Hz a 20 kHz) presentó un desafío.\nPara abordar este problema, diseñamos dos filtros pasa-todo en serie y calculamos los valores de los componentes para lograr la rotación de fase deseada en el rango de frecuencias objetivo.\nEl diseño fue modular para facilitar la integración con las etapas anteriores.\nProbamos el circuito en un protoboard antes de diseñar la PCB utilizando Altium Designer.\nEl dispositivo El dispositivo cuenta con varios controles para ajustar la fase y la ganancia. Tanto los ajustes de fase como de ganancia incluyen potenciómetros de ajuste fino para garantizar la máxima precisión.\n\u0026lsaquo;\r\u0026rsaquo;\rEstá equipado con entradas y salidas BNC, lo que permite a los usuarios visualizar la salida en un osciloscopio y lograr la máxima atenuación.\nResultados Este dispositivo se comparó con un medidor de THD comercial (GW INSTEK GAD-201G), y los resultados fueron muy similares. La principal limitación fue el nivel de ruido base del entorno de medición, que restringió significativamente el valor más bajo de THD que pudimos medir.\nLas especificaciones del dispositivo se resumen en la siguiente tabla (en español):\nUn análisis detallado del dispositivo está disponible en este informe.\n","date":"2024-11-26T00:00:00Z","image":"http://localhost:1313/p/thd-n-meter/port_hu1245660591834723805.jpeg","permalink":"http://localhost:1313/es/p/medidor-de-thd-n/","title":"Medidor de THD+N"},{"content":"Este estudio se realizó en el contexto de la clase Laboratorio de Acústica en la UNTREF. Elegí este tema porque está alineado con investigaciones que he estado desarrollando como parte del grupo Intercambios Transorgánicos. La consigna para el trabajo de clase consistió en realizar un estudio subjetivo utilizando una encuesta para explorar la relación entre variables objetivas y subjetivas.\nEn mi grupo de investigación, he estado investigando cómo los algoritmos de reducción de ruido afectan a los sistemas de síntesis de voz (TTS) entrenados con grabaciones de baja calidad. El enfoque está en el español rioplatense, un acento regional con datos de alta calidad limitados. En este contexto, fue natural combinar ambas tareas y realizar una prueba subjetiva sobre el impacto de los algoritmos de reducción de ruido en los sistemas TTS.\nResumen Los puntos clave de esta investigación son:\nEvaluación de tres algoritmos de reducción de ruido: Wave U-Net, HiFi-GAN y DeepFilterNet. Uso de métricas subjetivas (CMOS) y objetivas (PESQ, STOI, MCD). Ideas sobre el desarrollo de modelos TTS eficientes en recursos para acentos poco representados. Metodología Algoritmos: Wave U-Net, HiFi-GAN y DeepFilterNet evaluados con el modelo TTS FastPitch. Conjunto de datos: Subconjunto de la colección ArchiVoz (15 minutos de audio con ruido). Pruebas: Prueba subjetiva CMOS y métricas objetivas (PESQ, STOI, MCD). Participantes: 24 respuestas válidas, incluyendo tanto expertos como no expertos. Principales Hallazgos Rendimiento de DeepFilterNet:\nObtuvo la puntuación CMOS más alta, reflejando la mejor calidad subjetiva. Mostró mejoras significativas en la salida TTS a pesar de las correlaciones mixtas con las métricas objetivas. Análisis de Métricas Objetivas:\nPESQ y MCD mostraron una correlación limitada con las preferencias subjetivas. Las puntuaciones STOI fueron consistentes entre los algoritmos, indicando inteligibilidad preservada. Comparación de Algoritmos:\nDeepFilterNet: Evaluaciones subjetivas superiores, MCD moderado. Demucs: Comparable a DeepFilterNet en PESQ, pero con puntuaciones subjetivas inferiores. Wave U-Net: Bajo rendimiento tanto subjetivo como objetivo. Experiencia de los Participantes:\nNo se observaron diferencias significativas entre las evaluaciones subjetivas de expertos y no expertos. Implicaciones Eficiencia: Métodos avanzados de reducción de ruido como DeepFilterNet pueden mejorar los sistemas TTS sin necesidad de grabaciones de alta calidad. Limitaciones: Las métricas objetivas como PESQ y MCD no son indicadores suficientes por sí solas de la calidad subjetiva en TTS. Trabajo Futuro: Ampliar los conjuntos de datos y niveles de ruido para un análisis más robusto. Explorar sistemas TTS entrenados conjuntamente con algoritmos de reducción de ruido. Conclusiones Este trabajo concluye que el preprocesamiento con DeepFilterNet mejora significativamente el rendimiento de los sistemas TTS, con un aumento de 1.1 en la puntuación CMOS. Estos hallazgos destacan la importancia de la selección de algoritmos para optimizar sistemas TTS con pocos recursos. Además, adquirí valiosos conocimientos sobre evaluaciones subjetivas y el análisis estadístico necesario para extraer conclusiones significativas de los datos.\nToda la información de este estudio se encuentra en el informe académico (en inglés).\n","date":"2024-11-22T00:00:00Z","permalink":"http://localhost:1313/es/p/efecto-de-algor%C3%ADtmos-de-reducci%C3%B3n-de-rudio-en-sistemas-de-tts/","title":"Efecto de algorítmos de reducción de rudio en sistemas de TTS"},{"content":"\u0026ldquo;BassAdo\u0026rdquo; un parlante hogareño semi portable de bajo costo Este proyecto se enmarca en la materia Electroacústica II en UNTREF de la carrera Ingeniería de Sonido. La tarea era diseñar desde cero un altoparlante aplicando la teoría y conceptos explicados en clase. El trabajo se fue desarrollando durante todo el cuatrimestre con diferentes etapas a completar que se tenían que presentar con un informe. El parlante esta pensado para ser usado en un espacio grande, puede ser al aire libre, para poner música en un entorno de reunión. Se lo denomino Bassado para combinar el asado (típica comida argentina donde la gente se reune) y la palabra bass, enfatizando la característica del altoparlante.\nDiseño El objetivo es diseñar un sistema de audio hogareño con prestaciones accesibles, que permita explorar temas de interés abordados en la materia. El diseño busca lograr una predominancia en graves, característica de los sistemas comerciales, priorizando la extensión del ancho de banda en bajas frecuencias por encima de un bajo retardo de grupo y control temporal del sistema.\nCon respecto a los transductores a utilizar, el equipo contaba con unidades de la marca Yharo, que se pueden clasificar como no profesionales, consumidor-aficionado, con posibles aplicaciones en automóviles y/o sistemas hogareños. Se evalúa la respuesta en impedancia de los mismos y se selecciona un Woofer de 8” para cubrir la sección de bajas frecuencias, y dos de 4” para el rango de medias/altas.\nAl medir los parámetros de Thielle-Small de los altoparlantes se encuentra que tiene un Vas (Volumen Acústico Equivalente de Suspensión) muy alto, lo que requiere realizar un gabinete con mucho volumen para tener un buen control. Para solucionar este problema y dado la posibilidad de que se contaba con 2 Woofers de 8”, se decide hacer un altoparlante del tipo isobárico, colocando los 2 Woofers en serie acústicamente, para que tengan mayor control y poder hacer más chico el gabinete. Además, va a ser un gabinete ventilado para tener mejor respuesta en bajas.\nLa respuesta de los altoparlantes (paráemtros TS) fue obtenida en el software REW. Con esos parámetros, se simula en el software Basta! y se optimizan los parámetros para obtener la respuesta deseada. Lo principal fue sintonizar la frecuencia de resonancia del port, ya que el objetivo del altoparlante era tener una buena respuesta en bajas. El transductor tenía una fs en 45 Hz, y se busca sintonizar el port en 40 Hz controlando el largo del tubo y el volumen de aire del gabinete.\nEn base a estos resultados, se hace un modelo 3D del gabinete en el software SolidWorks con el que se manda a cortar las maderas para poder construir el gabinete.\nEl detalle de todo este proceso esta documentado en el siguiente informe de diseño.\nConstrucción Se mandaron a realizar los cortes a las maderas para hacer el gabinete según el modelo 3D y se realiza el ensamblado.\n\u0026lsaquo;\r\u0026rsaquo;\rComo se puede ver en las imágenes, se agregó lana de roca para hacer de absorbente acústico. Al realizar las mediciones nos dimos cuenta de que fue demasiado (la resonancia del port quedaba muy amortiguada) pero se le pudo sacar lana de roca hasta lograr el resultado deseado.\nMedición y Calibración Se realizaron mediciones de respuesta en frecuencia y de directividad en el laboratorio de la universidad, teníamos a disposición el siguiente equipamiento:\nPotencia Powersoft M50Q Micrófono Earthworks M50 Placa de Audio RME Fireface UCX Mesa Giratoria OUTLINE ET250-3D Con estas prestaciones y utilizando el software Arta, se pudo caracterizar la respuesta acústica de los transductores por separado (lo cual nos va a servir para simular los filtros de cruze). También se evalúa la respuesta directiva en el eje vertical y el horizontal para poder determinar cual es la mejor disposición para utilizar el dispositivo. Se realizaron gráficos de la respuesta para los dos transductores.\nTodas las respuestas y el análisis en profundidad se encuentran en el siguiente informe de medición.\nDiseño de filtro de cruce Por último, se diseña la etapa del filtro de curce. Con las mediciones realizadas previamente, se subieron los datos al software VituixCad. El objetivo del filtro de cruce es lograr una respuesta en frecuencia que suene agradable al reproducir un programa músical y que realce las bajas frecuencias. Se busca también, la mayor homogeneidad en la respuesta polar vertical.\nComo se va utilizar una etapa de potencia que requiere alimentación, se va a realizar un filtro de cruce activo con la topología Sallen-Key. Se definen una cantidad de filtros según el espacio y el costo y se realizan los ajustes en el software para obtener la respuesta deseada. Por ejemplo, para los drivers de baja frecuencia se realizó el siguiente arreglo:\nDonde:\nF1: Pasa altos fs=30 Hz | Q=0.67 F2: Pasa bajos fs=480 Hz | Q=0.5 F3: Elimina Banda 220 Hz F4: Elimina Banda 400 x Hz Antes de realizar el filtro, se probó la configuración planteada con un filtro digital para evaluar de forma práctica la respuesta del sistema según el diseño planteado. Todos los detalles de esta sección estan plasmados en el siguiente informe de filtro de cruce.\nConclusiones Con este trabajo, pudimos bajar muchos conceptos teóricos a la práctica y entender con más profundidad como es el desarrollo y los desafíos en un diseño de un sistema electroacústico.\n","date":"2024-11-20T00:00:00Z","image":"http://localhost:1313/p/building-and-design-of-a-personal-loudspeaker/front_bass_hu16513420204983711350.PNG","permalink":"http://localhost:1313/es/p/construcci%C3%B3n-y-dise%C3%B1o-de-un-altoparlante-personal/","title":"Construcción y diseño de un altoparlante personal"},{"content":"Entender un modelo moderno de deep learning no es sencillo debido a la gran cantidad de conocimiento previo necesario y al rápido ritmo de avance en este campo. En el proyecto de investigación Intercambios Transorgánicos, estamos trabajando con TTS, específicamente con el modelo FastPitch de Nvidia. He estudiado este modelo para ajustarlo (fine-tuning) al español y he compartido este proceso de investigación en una clase para ayudar a mis colegas del grupo de investigación a comprenderlo mejor.\nEntendiendo los Modelos Seq2Seq En Intercambios Transorgánicos utilizábamos previamente Tacotron2 como modelo TTS. Este modelo funciona bien, pero presenta varios problemas, principalmente durante el entrenamiento y la inferencia, debido a su naturaleza auto-regresiva. En contraste, FastPitch es un modelo no auto-regresivo (NAR). Para entender estas diferencias, exploré en profundidad los modelos seq2seq, analizando su evolución a lo largo del tiempo, y realicé un resumen rápido de los modelos de análisis de secuencias más relevantes:\nRNN LSTM Transformers Tacotron2 se basa en un modelo LSTM (AR), mientras que FastPitch utiliza Transformers (NAR). Comprender esta progresión tecnológica proporciona un contexto esencial, especialmente sobre los transformers, incluyendo la codificación posicional, un elemento clave para su naturaleza no auto-regresiva, y el mecanismo de atención.\nLa Arquitectura Transformer Comencé estudiando la arquitectura transformer, ya que es fundamental para el modelo FastPitch. Revisé recursos en línea y el influyente artículo Attention is All You Need. A continuación, algunos puntos clave que anoté durante mi estudio:\nMecanismo de Auto-Atención\nPropósito: Focalizar dinámicamente en diferentes partes de la secuencia de entrada. Mecanismo: Query (Q), Key (K), Value (V): Derivados de las embeddings de entrada. Los puntajes de atención se calculan como el producto punto de Q y K, escalado por la raíz cuadrada de la dimensión. Los puntajes se normalizan con softmax para generar pesos de atención. Se calcula una suma ponderada de V basada en estos pesos para producir la salida. Atención Multi-Cabezal\nPropósito: Capturar diferentes relaciones entre tokens aplicando múltiples mecanismos de auto-atención en paralelo. Mecanismo: Las salidas de las múltiples cabezas de atención se concatenan y se transforman linealmente. Codificación Posicional\nPropósito: Añadir información sobre el orden de los tokens en la secuencia, compensando la falta de un concepto incorporado de orden secuencial en los Transformers (a diferencia de los RNNs). Mecanismo: Se añade un vector fijo o aprendible a las embeddings de entrada. Estructura Codificador-Descodificador\nCodificador: Procesa la secuencia de entrada en representaciones ricas en contexto. Componentes: Auto-atención multi-cabezal Red neuronal feed-forward (FFN) Normalización por capas y conexiones residuales Descodificador: Genera la secuencia de salida atendiendo tanto a las salidas del codificador como a los tokens generados previamente. Componentes: Auto-atención multi-cabezal enmascarada (evita atender a tokens futuros) Atención multi-cabezal sobre las salidas del codificador FFN, normalización por capas y conexiones residuales Red Feed-Forward (FFN)\nPropósito: Introducir no linealidad y procesar cada token de manera independiente. Mecanismo: Dos capas lineales con una activación ReLU entre ellas. Normalización por Capas y Conexiones Residuales\nPropósito: Estabilizar el entrenamiento y mejorar el flujo de gradientes al normalizar las entradas de cada capa y añadir conexiones de salto. FastPitch Con la teoría cubierta, examiné cada sección de la arquitectura de FastPitch en detalle. Ofrecí una breve explicación sobre las embeddings de palabras y la codificación posicional, ya que son temas complejos, y quise mantener la clase concisa.\nFastPitch convierte texto en espectrogramas mel, que luego son transformados en audio por otro modelo (en nuestro caso, HiFi-GAN). La secuencia de entrenamiento incluye los siguientes pasos:\nTexto a embeddings de palabras Concatenación de embeddings de palabras con espectrogramas mel Codificación posicional y FFT (bloque Transformer Feed-Forward) Predicción de tono Predicción de la duración de los fonemas Otro bloque FFT Capa completamente conectada Salida del espectrograma mel En cada bloque, presenté las ecuaciones correspondientes y proporcioné explicaciones cualitativas sobre su rol en el modelo. Por ejemplo, la predicción de la duración de los fonemas es crucial para alinear la duración de un fonema con la duración esperada en el espectrograma.\nClase Online Finalmente, resumí los puntos más importantes y realicé una clase online para compartir estos conceptos con mis colegas. Puedes verla aquí:\n","date":"2023-08-23T00:00:00Z","image":"http://localhost:1313/p/understanding-fastpitch-and-the-transformer-architecture/front_hu1732994514150025714.png","permalink":"http://localhost:1313/es/p/entendiendo-fastpitch-y-la-arquitectura-transformers/","title":"Entendiendo FastPitch y la arquitectura Transformers"},{"content":"En el curso de Procesamiento Digital de Señales (DSP) en la UNTREF, exploramos el plano Z para el diseño de filtros con variables discretas. Durante la clase, el profesor presentó una herramienta construida en MatLab que visualiza los gráficos de transferencia y fase en relación con las posiciones de los ceros y polos en el plano Z.\nInspirado en esto, decidí recrear esta herramienta en Python. Aprovechando mi experiencia con la biblioteca PyGame, logré construir una aplicación en tiempo real que permite mover los polos y ceros, permitiendo a los usuarios ver cómo cambia la función de transferencia en tiempo real.\nCómo Funciona Primero, mapeo las posiciones de los píxeles en el plano Z a coordenadas de acuerdo con la representación del círculo unitario. Luego, construyo la función de transferencia, donde cada cero $z_{n}$ es un término en el numerador y cada polo $z_{i}$ es un término en el denominador. Con la función de transferencia $H(z)$, puedo graficar tanto el magnitud como el gráfico de fase, que también son representaciones mapeadas de la respuesta normalizada dentro de la aplicación.\n$$ H(z) = \\frac{\\sum_{n=0}^{N} (z - z_{n})}{\\sum_{i=0}^{N} (z - z_{i})}\r$$Cada fotograma recalcula la función de transferencia. El programa funciona de manera eficiente porque almaceno los ceros y polos en arreglos, lo que permite cálculos más rápidos gracias a numpy, que ya está altamente optimizado. Esto permite visualizar los cambios en tiempo real y proporciona una comprensión más intuitiva del comportamiento del plano Z. El siguiente fragmento de código muestra como se calcula la magnitud y fase utilizando exponenciales complejas.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def e(w, root): return (np.exp(1j*w) - root) def transfer_function(zeros, poles): w = np.linspace(-np.pi, np.pi, RES) for zero in zeros: num = e(w, zero) for pole in poles: den = e(w, pole) H_z = num/den mag = np.abs(H_z) ang = np.angle(H_z) return mag, ang Este proyecto está diseñado como material educativo, proporcionando a los estudiantes una herramienta práctica para comprender mejor las interacciones entre los polos y ceros en el plano Z. No está destinado como una herramienta profesional para el diseño de filtros.\nFuncionalidad La aplicación ofrece las siguientes características:\nMostrar y mover polos/ceros: Los usuarios pueden seleccionar y mover los polos y ceros en el plano Z. Cuando la opción de simetría está activa, todos los polos y ceros seleccionados o movidos se colocan de manera simétrica respecto al eje imaginario.\nOrden: Los usuarios pueden ajustar el orden de los polos y ceros desplazando la rueda del mouse. El orden puede incrementarse o disminuirse, con soporte hasta un orden de 4. El color de cada polo o cero cambia según su orden.\nInformación: Al pasar el cursor sobre un polo o cero, se muestra información sobre su posición, simetría y orden.\nZoom: El usuario puede acercar o alejar el plano Z usando los botones de más y menos.\nEliminar: El ícono de la papelera elimina todos los polos y ceros del plano. Los usuarios también pueden eliminar polos o ceros individuales haciendo clic derecho sobre ellos.\nGráfico de Magnitud: El espectro de magnitud mostrado en la aplicación está normalizado. Esta decisión asegura que el enfoque permanezca en la forma de la magnitud, haciendo que el gráfico sea visualmente significativo para los usuarios. Sin embargo, no captura la diferencia en los valores máximos.\nGráfico de Fase: La fase se muestra sin envolver entre $-\\pi$ y $\\pi$.\nDemo Aquí tienes una demostración rápida de la aplicación en acción:\nEl código fuente de este proyecto se encuentra en este repositorio.\n","date":"2023-08-12T00:00:00Z","image":"http://localhost:1313/p/z-plane-visualizer/frontz_hu11319941584083790054.PNG","permalink":"http://localhost:1313/es/p/z-plane-visualizer/","title":"Z-Plane Visualizer"},{"content":"Generador Automático de Rutinas de Ejercicio Este proyecto fue el trabajo final para la asignatura Algoritmos y Programación II en la UNTREF. La idea de la aplicación es funcionar como una planificación inteligente de rutinas de ejercicio, donde el usuario ingresa ciertos criterios y el programa establece la mejor rutina para maximizar las preferencias del usuario. El programa fue escrito en el lenguaje de programación Go.\nGestión de Datos Este curso no se centra en bases de datos, por lo que optamos por usar un archivo CSV para simular una base de datos. Este archivo contiene toda la información sobre las diferentes rutinas y sus atributos. Esto sirve como un archivo de persistencia mientras que toda la lógica es manejada por el programa.\nLos diferentes ejercicios están categorizados por temáticas. Hay dos entidades en el programa que están representadas como structs en Go: los Ejercicios y las Rutinas.\nEjercicio Todos los ejercicios tienen los siguientes atributos:\nNombre: Nombre del ejercicio. Descripción: Descripción detallada del ejercicio. Duración: Duración estimada del ejercicio. Calorías: Número de calorías quemadas durante el ejercicio. Tipo: Tipo de ejercicio (por ejemplo, cardio, fuerza, flexibilidad). Grupo Muscular: Grupo muscular objetivo del ejercicio. Puntos: Puntos asignados al ejercicio según sus tipos. Dificultad: Nivel de dificultad del ejercicio. Rutinas Todas las rutinas son una colección de ejercicios. Estas se procesan como una lista enlazada de ejercicios. Además, las rutinas tienen los siguientes atributos:\nNombre: Nombre de la rutina. Ejercicios: Cadena que almacena los IDs de los ejercicios en la rutina, separados por comas. EjerciciosDisponibles: Lista enlazada de los ejercicios disponibles para crear la rutina. Algoritmo La idea es maximizar diferentes parámetros, por ejemplo, la cantidad máxima de calorías quemadas en el menor tiempo posible, o la duración mínima para un grupo muscular o tipo de ejercicio específico. Para encontrar las mejores soluciones basadas en los datos existentes, proponemos un algoritmo de programación dinámica que busca todas las posibilidades a partir de los datos y encuentra el máximo o mínimo según las especificaciones del usuario. El enfoque de programación dinámica utiliza memoria para evitar recalcular combinaciones que ya fueron computadas, lo que optimiza el algoritmo lo suficiente como para generar las rutinas en milisegundos (con el conjunto de datos de prueba evaluado).\nInterfaz de Usuario Actualmente, el programa está diseñado para ser utilizado desde la terminal como una aplicación CLI. El usuario puede crear un ejercicio y una rutina, listar las opciones disponibles y generar una rutina personalizada basada en las especificaciones que elija.\nEsta es la primera iteración del proyecto y es completamente funcional, pero planeamos crear una interfaz gráfica para que sea más amigable para el usuario. Para este propósito, sería mejor usar un framework diferente y utilizar esta aplicación en Go como backend para un servicio web o una aplicación.\nConclusiones Con este proyecto, solidifiqué mis conocimientos sobre temas de programación como estructuras de datos y algoritmos, ya que aplicamos la teoría vista en clase a un caso real. También me ayudó a familiarizarme con el lenguaje Go, que se convirtió en un lenguaje que disfruto mucho programar. El código de este proyecto está disponible en este repositorio.\n","date":"2023-04-17T00:00:00Z","permalink":"http://localhost:1313/es/p/generador-de-ruitnas-de-entrenamiento-autom%C3%A1ticas/","title":"Generador de ruitnas de entrenamiento automáticas"},{"content":"Este proyecto comenzó como el trabajo final para un seminario de la UNTREF llamado Seminario en Aplicaciones de Redes Neuronales en la recuperación de información musical. El objetivo era utilizar una Red Neuronal Siamés (SNN, por sus siglas en inglés) en un contexto diferente al visto en clase (detección de similitud musical).\nPara el proyecto final de este curso, desarrollamos un modelo SNN desde cero utilizando el framework Keras y la arquitectura SincNet para reducir la dimensionalidad del audio, logrando buenos resultados. Más adelante, para expandir este proyecto, probé otro enfoque utilizando Wav2Vec para la reducción de dimensionalidad y reimplementé todo el proyecto en el framework PyTorch. Sin embargo, este intento arrojó resultados subóptimos, lo que indica que la reducción de dimensionalidad con Wav2Vec perdió información crítica necesaria para la tarea de diarización de locutores.\nTarea de Diarización de Locutores El objetivo de un modelo de diarización de locutores es identificar diferentes hablantes en un flujo de audio que contiene múltiples voces. Por ejemplo, en un podcast con dos personas (A y B), el modelo debe determinar los pasos de tiempo en los que el hablante A está hablando y los pasos de tiempo en los que el hablante B está hablando (e identificar implícitamente los períodos de silencio). Estos modelos son extremadamente útiles para la edición de audio y el análisis de largas secuencias de audio con múltiples hablantes.\n¿Por qué Redes Neuronales Siamés? En clase, exploramos la arquitectura siamés para comparar similitudes entre piezas musicales, desarrollando una herramienta capaz de identificar versiones de canciones famosas.\nUna Red Neuronal Siamés consiste en dos o más subredes idénticas que comparten los mismos pesos y parámetros. Está diseñada para comparar pares de entradas y medir su similitud, generalmente utilizando una métrica de distancia como la distancia euclidiana. Cada subred procesa una entrada, y las salidas se combinan para calcular un puntaje de similitud.\nCon esta comparación de similitudes en mente, quisimos aplicar estas redes a la tarea de diarización de locutores. La idea era generar embeddings de hablantes a partir de audio utilizando un modelo preentrenado y comparar las salidas de diferentes segmentos de audio. Basándonos en el puntaje de similitud, buscamos identificar los segmentos donde diferentes hablantes están hablando.\nExperimentos Probé dos métodos diferentes para la extracción de características de audio que servirían como embeddings de hablantes.\nImplementación en Keras con SincNet En este enfoque, utilizamos la arquitectura SincNet para extraer características específicas de los hablantes a partir del audio. SincNet aplica funciones sinc aprendibles como sus filtros, que son particularmente adecuadas para el procesamiento de audio, ya que imitan los filtros de paso de banda tradicionales. Estas características se introdujeron en la Red Neuronal Siamés, que comparó pares de segmentos de audio para calcular sus puntajes de similitud. El modelo se entrenó con conjuntos de datos de audio etiquetados y observamos un rendimiento sólido al agrupar segmentos de audio por hablante, logrando límites claros entre diferentes hablantes.\nUn informe con los resultados puede encontrarse en el siguiente notebook de Jupyter (en español).\nImplementación en PyTorch con Wav2Vec Para este método, utilicé Wav2Vec, un modelo preentrenado poderoso para la extracción de embeddings profundos de audio. A diferencia de SincNet, los embeddings de Wav2Vec se derivan del aprendizaje autosupervisado, capturando representaciones de alto nivel del audio. Estos embeddings se usaron en la Red Neuronal Siamés para comparaciones de similitud. Sin embargo, los resultados fueron subóptimos para la tarea de diarización. Parece que Wav2Vec, aunque excelente para tareas de reconocimiento de voz, perdió algunos detalles específicos del hablante necesarios para distinguir entre diferentes voces en nuestro contexto.\nResultados Los experimentos demostraron que la elección del método de extracción de características es crucial para la diarización de locutores. La implementación en Keras con SincNet superó a la implementación en PyTorch con Wav2Vec, mostrando mayor precisión al identificar transiciones entre hablantes. Esto sugiere que la extracción de características específicas para la tarea, como SincNet, es más efectiva que los embeddings de propósito general como Wav2Vec para la diarización de locutores.\nEl código de este proyecto está disponible en este repositorio.\nConclusiones Este proyecto fue una de mis primeras experiencias con modelos de aprendizaje profundo, donde apliqué mis conocimientos a un problema sin seguir un artículo específico o utilizar un modelo preentrenado. Exploré diferentes soluciones y concluí sobre la importancia de la extracción de características y la selección del modelo.\nTambién me ayudó a familiarizarme con la sintaxis de los frameworks de aprendizaje profundo más populares y a solidificar mi comprensión en el proceso.\n","date":"2022-11-04T00:00:00Z","permalink":"http://localhost:1313/es/p/evaluaci%C3%B3n-de-diferentes-modelos-de-separaci%C3%B3n-del-hablante/","title":"Evaluación de diferentes modelos de Separación del Hablante"},{"content":"Este proyecto es el trabajo final de la clase Acústica y Psicoacústica II, donde se nos encargó rediseñar un auditorio existente. El objetivo era aplicar la teoría vista en clase para crear un auditorio optimizado desde el punto de vista acústico. Para nuestro proyecto, elegimos rediseñar el Royal Albert Hall en Londres. Esto representó un desafío particular debido a las grandes dimensiones del auditorio, lo que dificulta asegurar que el sonido llegue de manera uniforme a todos los espectadores.\nIdeas Principales del Rediseño El rediseño buscó preservar el concepto original del auditorio, incluyendo su gran volumen y capacidad de asientos, mientras se introducían cambios críticos para mejorar su acústica. Aunque el enfoque principal fue la mejora acústica, el rediseño también consideró otros factores esenciales, como las líneas de visión y una distribución adecuada de los asientos.\nA pesar de la intención de mantener las dimensiones originales del auditorio, su volumen resultó ser demasiado grande para lograr un tiempo de reverberación óptimo. Para abordar este problema, el rediseño incorporó un techo intermedio para reducir el volumen del techo esférico, y se redujo el área principal de asientos. Estos cambios permitieron obtener un mejor tiempo de reverberación en la sala, como se ilustra en la sección transversal a continuación.\nDetalles de Construcción y Regulaciones Para garantizar un rediseño factible y funcional, se consideraron cuidadosamente los siguientes aspectos clave:\nDistribución de asientos Espaciado de los pasillos Optimización de las líneas de visión Comodidad del escenario Tratamiento Acústico El tratamiento acústico fue la parte más crítica de este estudio y se centró en dos aspectos principales: reflexiones y tiempo de reverberación.\nReflexiones El análisis de las reflexiones es esencial para la experiencia acústica del público. El Royal Albert Hall original cuenta con un techo esférico que centraliza las reflexiones, creando efectos acústicos indeseables. Para mitigar esto, el rediseño incorporó un techo intermedio con una geometría específica diseñada para distribuir las reflexiones de manera uniforme entre el público.\nEl diseño escalonado del techo garantiza reflexiones adecuadas para todas las filas de asientos. En el balcón principal, se abordaron dos reflexiones específicas para compensar el menor nivel de presión sonora (SPL) debido a la gran distancia desde el escenario, como se muestra en la imagen a continuación.\nTambién se optimizaron las reflexiones laterales mediante ajustes en la geometría del escenario y las paredes de los balcones laterales.\nAdemás, el rediseño buscó minimizar el ITDG (Initial Time Delay Gap) en los diferentes puntos del público.\nMateriales y Tiempo de Reverberación El rediseño siguió las recomendaciones del libro Acoustic Absorbers and Diffusers para lograr un equilibrio entre absorción, difusión y reflexiones especulares. Se utilizaron materiales reflectantes en el techo y en partes de los balcones laterales para garantizar reflexiones especulares efectivas. Para reducir el tiempo de reverberación (RT), se aplicaron materiales con coeficientes de absorción más altos en otras superficies.\nUsando los materiales seleccionados y la ecuación de Sabine, calculamos el RT estimado del auditorio. El tiempo de reverberación para las diferentes frecuencias se muestra a continuación:\nEl RT calculado para frecuencias medias es de 2,51 segundos. Aunque este valor está ligeramente por encima del máximo recomendado de 2,4 segundos para una acústica óptima, es aceptable dado el gran volumen del auditorio.\nModelado 3D Renderizamos el auditorio rediseñado utilizando el software SketchUp. A continuación, se presentan algunas visualizaciones:\n\u0026lsaquo;\r\u0026rsaquo;\rConclusiones Rediseñar el Royal Albert Hall para mejorar su acústica mientras se preserva su esencia original presentó desafíos significativos. El proyecto requirió soluciones innovadoras para abordar los problemas acústicos sin comprometer el diseño icónico del auditorio. Aunque fueron necesarios algunos cambios, el resultado final demuestra un rediseño cuidadosamente pensado que mejora la acústica mientras mantiene el carácter histórico del Royal Albert Hall. Este proyecto también profundizó nuestra comprensión de los conceptos de acústica y diseño de auditorios.\nUna descripción detallada de este proyecto está disponible en el siguiente artículo (en inglés).\n","date":"2022-06-22T00:00:00Z","image":"http://localhost:1313/p/theather-acoustic-design/front_hu7206688613610463615.PNG","permalink":"http://localhost:1313/es/p/dise%C3%B1o-de-un-auditorio/","title":"Diseño de un auditorio"},{"content":"Time Scale Modification (TSM) Time scale modifications algorithms\nAlgorithm comparison OLA PV\nResults Very good\nAcademic Presentation Paper y Presentación en JAAS\n","date":"2019-03-09T00:00:00Z","image":"http://localhost:1313/p/time-scale-modification-algorithms/tsm_hu16003083865389877412.PNG","permalink":"http://localhost:1313/es/p/algor%C3%ADtmos-de-modificaci%C3%B3n-de-escala-temporal/","title":"Algorítmos de modificación de escala temporal"}]