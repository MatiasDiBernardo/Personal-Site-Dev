<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Academic on Matias Di Bernardo</title>
        <link>http://localhost:1313/tags/academic/</link>
        <description>Recent content in Academic on Matias Di Bernardo</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>Matías Di Bernardo</copyright>
        <lastBuildDate>Fri, 22 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/academic/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>The effect of denosing on TTS</title>
        <link>http://localhost:1313/p/the-effect-of-denosing-on-tts/</link>
        <pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/the-effect-of-denosing-on-tts/</guid>
        <description>&lt;p&gt;This study was conducted in the context of the class &lt;em&gt;Laboratorio de Acústica&lt;/em&gt; at UNTREF. I chose this topic because it aligns with research I have been pursuing as part of the group &lt;em&gt;Intercambios Transorgánicos&lt;/em&gt;. The class assignment involved conducting a subjective study using a survey to explore the relationship between objective and subjective variables.&lt;/p&gt;
&lt;p&gt;In my research group, I have been investigating how denoising algorithms affect Text-to-Speech (TTS) systems trained on low-quality recordings. The focus is on Rioplatense Spanish, a regional accent with limited high-quality data. Within this context, it was natural to combine both tasks and perform a subjective test on the impact of denoising algorithms on TTS systems.&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview
&lt;/h2&gt;&lt;p&gt;The key points of this investigation are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluation of three denoising algorithms: Wave U-Net, HiFi-GAN, and DeepFilterNet.&lt;/li&gt;
&lt;li&gt;Use of both subjective (CMOS) and objective metrics (PESQ, STOI, MCD).&lt;/li&gt;
&lt;li&gt;Insights into resource-efficient TTS model development for underrepresented accents.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methodology&#34;&gt;Methodology
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Algorithms&lt;/strong&gt;: Wave U-Net, HiFi-GAN, and DeepFilterNet evaluated with the FastPitch TTS model.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dataset&lt;/strong&gt;: Subset of the ArchiVoz collection (15 minutes of noisy audio).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Testing&lt;/strong&gt;: CMOS subjective test and objective metrics (PESQ, STOI, MCD).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Participants&lt;/strong&gt;: 24 valid responses, including both experts and non-experts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;key-findings&#34;&gt;Key Findings
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DeepFilterNet Performance&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Achieved the highest CMOS score, reflecting the best subjective quality.&lt;/li&gt;
&lt;li&gt;Demonstrated significant improvements in TTS output despite mixed correlations with objective metrics.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Objective Metrics Analysis&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PESQ and MCD showed limited correlation with subjective preferences.&lt;/li&gt;
&lt;li&gt;STOI scores were consistent across algorithms, indicating preserved intelligibility.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Algorithm Comparisons&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DeepFilterNet&lt;/strong&gt;: Superior subjective evaluations, moderate MCD.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Demucs&lt;/strong&gt;: Comparable to DeepFilterNet in PESQ but lower subjective scores.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wave U-Net&lt;/strong&gt;: Poor subjective and objective performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Subject Expertise&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No significant differences were observed between expert and non-expert evaluations in subjective testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;implications&#34;&gt;Implications
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;: Advanced denoising methods like DeepFilterNet can enhance TTS systems without requiring high-quality recordings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limitations&lt;/strong&gt;: Objective metrics like PESQ and MCD are insufficient standalone indicators of subjective TTS quality.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Future Work&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Expand datasets and noise levels for more robust analysis.&lt;/li&gt;
&lt;li&gt;Explore TTS systems trained jointly with denoising algorithms.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions
&lt;/h2&gt;&lt;p&gt;This work concludes that preprocessing with DeepFilterNet significantly improves TTS performance, with a 1.1 CMOS score increase. These findings underscore the importance of algorithm selection in optimizing low-resource TTS systems. Additionally, I gained valuable insights into subjective evaluations and the statistical analysis required to draw meaningful conclusions from data.&lt;/p&gt;
&lt;p&gt;All the information for this study can be found in the &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1F4aJGIU9FX2LT8OFik-Yjg4uSz6T09jw/view?usp=sharing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;academic report&lt;/a&gt;.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Time Scale Modification Algorithms</title>
        <link>http://localhost:1313/p/time-scale-modification-algorithms/</link>
        <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/time-scale-modification-algorithms/</guid>
        <description>&lt;img src="http://localhost:1313/p/time-scale-modification-algorithms/tsm.PNG" alt="Featured image of post Time Scale Modification Algorithms" /&gt;&lt;p&gt;Time scale modifications algorithms are used to speed up or slow down the reproduction velocity of an audio. When you change the sample rate of an audio, the velocity changes but it also changes the pitch (when the audio is speed up it sounds highier pitch). There are different algorithms that change the velocity of the audio but mantain the pitch.&lt;/p&gt;
&lt;p&gt;The main reference for this study is the following article, where all the different algorithms are describe in detail.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Review of Time-Scale Modification of Music Signals.&lt;br&gt;
— &lt;cite&gt;Jonathan Driedger and Meinard Müller&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;algorithm-comparison&#34;&gt;Algorithm comparison
&lt;/h2&gt;&lt;p&gt;There are two main algorithms, the &lt;em&gt;Overlap-and-add&lt;/em&gt; (OLA) and the &lt;em&gt;Phase Vocoder&lt;/em&gt; (PV). Both achieve good results under different signals and conditions. For this, a final implementation using &lt;em&gt;Harmonic Percussion Separation&lt;/em&gt; (HPS) combines both algorithms and achiving the best results.&lt;/p&gt;
&lt;h3 id=&#34;ola&#34;&gt;OLA
&lt;/h3&gt;&lt;p&gt;This method works on time domain and overlap sections of the audio (windows) and rearange it to achive a certain desire change on speed. This method works well for percussive signals, but it introduces artifacts when used with harmonic or tonal signals.&lt;/p&gt;
&lt;h3 id=&#34;pv&#34;&gt;PV
&lt;/h3&gt;&lt;p&gt;This method works on frequency domain, and it combines chunks of audio in the frequency domain to achieve the desire change in time. This uses the phase vocoder principle to propagate the phase between the windows, this grantice the continuity of when applied to harmonic signals. On the contrary, it does not work for percussive signals becouse the phase propagation process eliminate the transients in the signals.&lt;/p&gt;
&lt;p&gt;I created visualizations using &lt;em&gt;Manim&lt;/em&gt; to enhance my class presentation. The first video demonstrates how the PV algorithm aligns windows to ensure smooth transitions in the generated signal over time. To achieve this, a Gaussian window is applied, which maintains continuity and smoothness, even at the start and end of the sequence.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://player.vimeo.com/video/1045495557&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;vimeo video&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The second video showcases the effects of applying the PV algorithm to a signal containing transients.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://player.vimeo.com/video/1045495634&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;vimeo video&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;As predicted by theory, the transients vanish because the PV algorithm disrupts the vertical phase alignment. While these examples utilize idealized signals, they effectively demonstrate the key strengths and limitations of the algorithm.&lt;/p&gt;
&lt;h3 id=&#34;hps&#34;&gt;HPS
&lt;/h3&gt;&lt;p&gt;To use both methods with their ideal signals, the HPS algorithms is used. This algorithm separete the signal into the harmonics and the percussive parts. It works by comparing the continuty of the signal in the STFT representation and using a filter to compare vertical versus horizontal presence on the spectrogram. With a threshold, a binary mask can be define over the spectrogram to separete the percussive parts from the harmoincs sections.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results
&lt;/h2&gt;&lt;p&gt;We succesfully implement all the algorithms and compare them, verifying the theortical contents presented on the referenca article. In the process, we develope the toolkit to use this algorithms with the python programming language. All the code is avaliable on this &lt;a class=&#34;link&#34; href=&#34;https://github.com/MatiasDiBernardo/TSM_Toolkit&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;repo&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;academic-presentation&#34;&gt;Academic Presentation
&lt;/h2&gt;&lt;p&gt;The study was preseented with my classmates on the &lt;em&gt;JAAS&lt;/em&gt; (Jornadas de Acustica, Audio y Sonido). The main ideas and conclusions were preseneted on the conference. In the following repoert there is all the details and anlysis done for this proyect (in spanish).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ALGORITMOS DE MODIFICACIÓN DE ESCALA TEMPORAL.&lt;br&gt;
— &lt;cite&gt;Matías Di Bernardo; Matías Vereertbruhggen; Sebastían Carro &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;A Review of Time-Scale Modification of Music Signal &lt;a class=&#34;link&#34; href=&#34;https://www.researchgate.net/publication/295082364_A_Review_of_Time-Scale_Modification_of_Music_Signals&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;paper&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;JAAS 2023 - Algoritmos de Modificación de Escala Temporal &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/12kPB3qBjczyx7X2XV3ZpBDo1GDO2u4qR/view?usp=sharing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;paper&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
        </item>
        <item>
        <title>Comparative analysis of time-frequency transformations</title>
        <link>http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/</link>
        <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/</guid>
        <description>&lt;img src="http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/fourier.jpg" alt="Featured image of post Comparative analysis of time-frequency transformations" /&gt;&lt;p&gt;This research is conducted as part of the subject &lt;em&gt;Metodología de la Investigación&lt;/em&gt; at UNTREF. The article aims to compare the differences between three types of time-frequency transformations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fourier Transform (FT)&lt;/li&gt;
&lt;li&gt;Wavelet Transform (WT)&lt;/li&gt;
&lt;li&gt;Huang-Hilbert Transform (HHT)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The objective of this work is to understand the differences between these types of transformations and deepen my knowledge of signal processing.&lt;/p&gt;
&lt;h2 id=&#34;objective&#34;&gt;Objective
&lt;/h2&gt;&lt;p&gt;The general objective of the research is to determine which spectral analysis tool achieves the highest accuracy in pitch detection tasks.&lt;/p&gt;
&lt;p&gt;To achieve this objective, the following specific objectives are proposed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify the parameters needed to represent the signal in the spectral domain for each case.&lt;/li&gt;
&lt;li&gt;Select an algorithm that identifies the pitch of the signal based on its spectral representation.&lt;/li&gt;
&lt;li&gt;Generate the data (audio signals) to be used for the comparison.&lt;/li&gt;
&lt;li&gt;Evaluate the generated data with the different analysis methods and apply statistical processes to validate the results.&lt;/li&gt;
&lt;li&gt;Establish a measure of accuracy for the pitch detection task.&lt;/li&gt;
&lt;li&gt;Compare the results of the different analyses and determine which method achieves the highest accuracy in pitch detection.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pitch detection task was chosen because it is one of the main applications of these types of transformations.&lt;/p&gt;
&lt;h2 id=&#34;algorithms&#34;&gt;Algorithms
&lt;/h2&gt;&lt;p&gt;The theoretical analysis of all the transformations is performed in the continuous domain, but to conduct the experiments and comparisons, the discrete domain is used, enabling all calculations to be performed digitally.&lt;/p&gt;
&lt;h3 id=&#34;fft&#34;&gt;FFT
&lt;/h3&gt;&lt;p&gt;The FFT is an algorithm that optimizes the DFT (Discrete Fourier Transform). With this algorithm, the spectral representation of the signal is obtained according to Fourier analysis, which decomposes a complex signal into a sum of sines or cosines. The DFT is calculated using the formula:&lt;/p&gt;
$$
X_k = \sum_{n=0}^{N-1} e^{-i\frac{2\pi}{N}kn} x_n
$$&lt;p&gt;Where \( N \) is the number of signal samples, and \( k \) are natural numbers from \( 0 \) to \( N – 1 \).&lt;/p&gt;
&lt;h3 id=&#34;wt&#34;&gt;WT
&lt;/h3&gt;&lt;p&gt;The Wavelet Transform (WT) uses an oscillatory function (wavelet) and applies a convolution between the signal and the chosen wavelet function to determine whether that wave shape is present in the signal. The wavelet is stretched and scaled in frequency and amplitude, allowing a single wavelet function to recreate the entire spectrum of interest.&lt;/p&gt;
&lt;p&gt;In this research, the CDWT (Cyclic Discrete Wavelet Transform) will be used, the most common implementation when discretizing the WT. Conceptually, this transform extends Fourier analysis by projecting the signal onto a basis of wavelet functions instead of sines and cosines. It is calculated as follows:&lt;/p&gt;
$$
Wf[n, a^j] = \sum_{m=0}^{N-1} f[m] \psi_j[m-n]
$$&lt;p&gt;Where \( N \) is the number of signal samples, \( \psi \) is the wavelet function, and \( j \) represents the deformation of the wavelet according to the selected wavelet bank.&lt;/p&gt;
&lt;h3 id=&#34;hht&#34;&gt;HHT
&lt;/h3&gt;&lt;p&gt;Lastly, the Huang-Hilbert Transform (HHT) will be used for spectral representation. It employs a method called Empirical Mode Decomposition (EMD) to decompose the signal into subsignals that contain the relevant information of the original function.&lt;/p&gt;
&lt;p&gt;Like the previous analysis methods, the key part of the analysis is the decomposition of the signal into simpler signals. However, instead of sine or wavelet functions, EMD finds intrinsic mode functions (IMFs) that form the basis of our decomposition and are unique to each signal.&lt;/p&gt;
&lt;p&gt;The relationship between the IMFs and the frequency of the original signal is established with the equation:&lt;/p&gt;
$$
z(t) = f(t) + i H\{ f(t) \}
$$&lt;p&gt;Where \( f(t) \) is an IMF of the original signal, and \( H \) is the Hilbert Transform. This allows the IMF to be represented as a complex signal by projecting it onto the imaginary axis using the Hilbert Transform.&lt;/p&gt;
&lt;p&gt;Thus, the IMF is represented as a complex signal, and the amplitude and phase of each moment can be extracted to construct the spectral representation. Since a signal generally has multiple IMFs, this process is repeated for all of them, and the results are summed to obtain the complete spectrum.&lt;/p&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure
&lt;/h2&gt;&lt;p&gt;This research analyzes the relationship between types of spectral representation and accuracy in pitch detection.&lt;/p&gt;
&lt;p&gt;First, the parameters for the different transformations will be selected. Among the most critical parameters to determine is the number of samples for temporal windowing, as it determines the trade-off between temporal and frequency resolution.&lt;/p&gt;
&lt;p&gt;To ensure a fair comparison among the methods, data representing various cases of interest will be generated, including four types of signals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Monophonic&lt;/strong&gt;: Signals with a single note corresponding to \( F_0 \).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Polyphonic&lt;/strong&gt;: Signals with multiple notes where harmony determines \( F_0 \).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Slow Transitions&lt;/strong&gt;: Signals with gradual changes in \( F_0 \).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast Transitions&lt;/strong&gt;: Signals with abrupt changes in \( F_0 \).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The real value \( V(t) \) will be compared to the result \( P(t) \) from each transform, integrating the difference over time to calculate the accuracy.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results
&lt;/h2&gt;&lt;p&gt;At this stage, the task was to complete the research plan detailing the procedure and analysis methods. Dummy data was generated and statistically validated to simulate expected results.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/res.PNG&#34;
	width=&#34;834&#34;
	height=&#34;550&#34;
	srcset=&#34;http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/res_hu8387233291062647437.PNG 480w, http://localhost:1313/p/comparative-analysis-of-time-frequency-transformations/res_hu2809804783985204141.PNG 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Graph showing the precision of each transform according to the type of signal analyzed&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;363px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;The graph compares the precision achieved by the three transformations for different signal types. Based on the properties of the transforms, the Wavelet Transform (WT) is expected to outperform the Fourier Transform (FT), and the Huang-Hilbert Transform (HHT) is expected to achieve the highest precision overall.&lt;/p&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions
&lt;/h2&gt;&lt;p&gt;In pitch detection tasks using spectral analysis, the Huang-Hilbert Transform (HHT) generally provides higher precision than the Fast Fourier Transform (FFT) and the Cyclic Discrete Wavelet Transform (CDWT).&lt;/p&gt;
&lt;p&gt;The significance of this precision gain depends on the type of signal being analyzed, with fast-transition signals benefiting the least from the transformation change, while polyphonic signals show the most significant improvement when using the HHT.&lt;/p&gt;
&lt;p&gt;This project allowed me to deepen my understanding of signal processing and grasp the foundations of why tools like the WT and HHT are used based on the characteristics of the signal being analyzed.&lt;/p&gt;
&lt;p&gt;All details of this work are available in the following &lt;a class=&#34;link&#34; href=&#34;https://drive.google.com/file/d/1G5kasP3BzZPVuxrXArHM72pUVlkN9b2Q/view?usp=sharing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;report&lt;/a&gt;.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
